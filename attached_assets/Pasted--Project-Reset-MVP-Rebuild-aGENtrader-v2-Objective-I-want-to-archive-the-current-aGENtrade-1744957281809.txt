🛠️ Project Reset & MVP Rebuild: aGENtrader_v2
🎯 Objective:
I want to archive the current aGENtrader codebase as version 1 and start with a clean, minimal backend architecture focused only on core AI-enhanced trading decision-making.

This version (v2) will be modular, agent-driven, and powered by AutoGen Core with mock or local LLM support during development, and production-ready deployment to EC2 once tested.

🗃️ Phase 1: Archive & Clean Up
Archive the current implementation under a new subfolder and commit to GitHub:

Folder name: aGENtrader_v1

Retain version history and file structure

Set up a fresh and minimal root structure for aGENtrader (v2) with no frontend or UI code. The focus is purely backend.

Retain the existing SQLite or Postgres DB already populated with historical market data. Do not delete or reset this.

Clean the Replit environment:

Remove virtual environments (.venv, .mypy_cache, __pycache__, poetry.lock, etc.)

Remove or archive the old requirements.txt

Create a minimal, fresh requirements.txt including only essential dependencies:

autogen

autogen-ext

requests

sqlite3 (or relevant DB lib)

Optional: openai for later use

🧠 Phase 2: Backend MVP Implementation
Goal: Deliver a minimal working pipeline where AI agents process real market data and return a structured trading decision using AutoGen Core.

🔁 MVP Workflow:
The Orchestrator sends an event to:

MarketAnalystAgent

LiquidityAnalystAgent

(Later additions: OnChainAnalystAgent, SentimentAnalystAgent)

Each agent uses:

A local or mock LLM via a centralized LLMClient abstraction

PythonCodeExecutor via autogen_ext.executors to analyze or simulate logic

The DecisionAgent collects outputs and produces:

json
Copy
Edit
{
  "action": "BUY",
  "pair": "BTC/USDT",
  "confidence": 87,
  "reason": "Strong market structure + deep liquidity detected"
}
The decision is logged or printed for now — no actual trading execution in this stage.

🧩 Additional LLM Considerations:
Due to Replit’s RAM/storage limits, do not attempt to run large local models (e.g., Mixtral) inside Replit.

Instead:

Use TinyLlama or a mock LLM response for dev/testing.

Implement an LLMClient abstraction module that supports:

"mock" for fast development

"ollama" for local testing on EC2 (e.g., Mixtral, Mistral)

"openai" for remote API support (optional, post-MVP)

This lets you build once, and swap models/configs later.

📂 Suggested Folder Structure:
bash
Copy
Edit
aGENtrader/
├── agents/
│   ├── market_analyst_agent.py
│   ├── liquidity_analyst_agent.py
│   └── decision_agent.py
├── executors/
│   ├── python_executor.py
│   └── trade_executor.py
├── models/
│   └── llm_client.py           # Abstraction layer for mock/openai/ollama
├── orchestrator/
│   └── core_orchestrator.py
├── data/                       # Retain existing market data here
├── config/
│   └── settings.yaml
├── logs/
├── requirements.txt
├── README.md
├── run.py
└── aGENtrader_v1/              # Archived version of previous codebase
✅ Tasks for You (Replit Agent):
Archive and restructure the project as described

Reset environment and generate a fresh requirements.txt

Implement:

One working agent (LiquidityAnalystAgent)

LLMClient with at least a "mock" mode

A minimal orchestrator that sends an event and receives the decision

Log all outputs to file (e.g., logs/agent_output.log) to avoid Replit console truncation issues

Comment all code for extensibility

Once this MVP is working:

I will port it to EC2

Swap the LLMClient to "ollama" for Mixtral

Extend to include real-time market data and full trade execution

Start by listing the cleanup and implementation plan, then proceed step-by-step.